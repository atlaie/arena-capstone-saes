Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f273bef6f50>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f2a9ef14af0, execution_count=2 error_before_exec=None error_in_exec=Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`labels` in this case) have excessive nesting (inputs type `list` where type `int` is expected). info=<ExecutionInfo object at 7f288b388040, raw_cell="#%%
trainer = Trainer(
    model=model,
    token.." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-1.interactive#X13sdW50aXRsZWQ%3D> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f273bef6f50>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f293384ad10, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "Trainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "train_frac", "type": "float", "fullType": "float"}, {"name": "trainer", "type": "Trainer", "fullType": "transformers.trainer.Trainer"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f273bef6f50>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f2730856dd0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f293384ad10, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f273bef6f50>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f2730999240, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "Trainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "train_frac", "type": "float", "fullType": "float"}, {"name": "trainer", "type": "Trainer", "fullType": "transformers.trainer.Trainer"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f273bef6f50>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f2730999450, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f2730999240, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f273bef6f50>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f273b27ceb0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "Trainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "train_frac", "type": "float", "fullType": "float"}, {"name": "trainer", "type": "Trainer", "fullType": "transformers.trainer.Trainer"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f273bef6f50>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f273b27e2f0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f273b27ceb0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f273bef6f50>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f273d5c6fe0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "Trainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "train_frac", "type": "float", "fullType": "float"}, {"name": "trainer", "type": "Trainer", "fullType": "transformers.trainer.Trainer"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
