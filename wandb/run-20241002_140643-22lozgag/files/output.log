Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f75ba7f4460, execution_count=1 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f75d3dde7a0, raw_cell="#%%
# ============================================.." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-2.interactive#X13sdW50aXRsZWQ%3D> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f7311231d80, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f7311230a90, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f7311231d80, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f7328157880, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f73281558a0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f7328157880, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f732821dc30, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f732821cf10, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f732821dc30, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f7318cc9720, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f7318cc9780, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f7318cc9720, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f7330914a00, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f7330915150, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f7330914a00, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f73201624d0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f7320163e80, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f73201624d0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f736014c7c0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f736014e5c0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f736014c7c0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f7319d4c730, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f7319d4fe50, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f7319d4c730, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f75d3985750, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f75d39846d0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f75d3985750, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f73304668c0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f73304675e0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f73304668c0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f73380b9660, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f73380b92d0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f73380b9660, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f7350171330, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f7350171870, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f7350171330, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f73283ecc10, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f73283ecd90, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f73283ecc10, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f736014d6f0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f736014c7c0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f736014d6f0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f731888b7c0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f7330e346a0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f731888b7c0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f7328c182e0, raw_cell="#%%
model.save_pretrained("./gemma-2-2b-it_noLoRa.." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-2.interactive#X14sdW50aXRsZWQ%3D>,),kwargs {}:
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f7328c1ba30, execution_count=2 error_before_exec=None error_in_exec=
            Some tensors share memory, this will lead to duplicate memory on disk and potential differences when loading them again: [{'model.embed_tokens.weight', 'lm_head.weight'}].
            A potential way to correctly save your model is to use `save_model`.
            More information at https://huggingface.co/docs/safetensors/torch_shared_tensors
             info=<ExecutionInfo object at 7f7328c182e0, raw_cell="#%%
model.save_pretrained("./gemma-2-2b-it_noLoRa.." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-2.interactive#X14sdW50aXRsZWQ%3D> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f73402bb8b0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f73402ba050, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f73402bb8b0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f73402b8cd0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f7330e0b7f0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f73402b8cd0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f7340346ad0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f737621ffa0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f7340346ad0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f7311a57550, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f7311a571f0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f7311a57550, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f7358726b60>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f7318228970, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
