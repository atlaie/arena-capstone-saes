<bound method Module.named_modules of PeftModelForCausalLM(
  (base_model): LoraModel(
    (model): Gemma2ForCausalLM(
      (model): Gemma2Model(
        (embed_tokens): Embedding(256000, 2304)
        (layers): ModuleList(
          (0-25): 26 x Gemma2DecoderLayer(
            (self_attn): Gemma2Attention(
              (q_proj): Linear(in_features=2304, out_features=2048, bias=False)
              (k_proj): Linear(in_features=2304, out_features=1024, bias=False)
              (v_proj): Linear(in_features=2304, out_features=1024, bias=False)
              (o_proj): Linear(in_features=2048, out_features=2304, bias=False)
              (rotary_emb): GemmaFixedRotaryEmbedding()
            )
            (mlp): Gemma2MLP(
              (gate_proj): Linear(in_features=2304, out_features=9216, bias=False)
              (up_proj): Linear(in_features=2304, out_features=9216, bias=False)
              (down_proj): lora.Linear(
                (base_layer): Linear(in_features=9216, out_features=2304, bias=False)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=9216, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=2304, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict()
              )
              (act_fn): PytorchGELUTanh()
            )
            (input_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)
            (post_attention_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)
            (pre_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)
            (post_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)
          )
        )
        (norm): Gemma2RMSNorm((2304,), eps=1e-06)
      )
      (lm_head): Linear(in_features=2304, out_features=256000, bias=False)
    )
  )
)>
Training completed in 1291.2333 seconds.
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f0929e8a410>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f092b7c8ee0, execution_count=3 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f092b7c9ba0, raw_cell="#%%
trainer = SFTTrainer(
    model=model,
    to.." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-1.interactive#X16sdW50aXRsZWQ%3D> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f0929e8a410>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f08e91e15a0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f0929e8a410>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f08e91e1420, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f08e91e15a0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f0929e8a410>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f08f1d432b0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f0929e8a410>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f08f1d403a0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f08f1d432b0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f0929e8a410>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f08e099e0e0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f0929e8a410>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f08e099ea40, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f08e099e0e0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f0929e8a410>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f08e9cf5ae0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f0929e8a410>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f08e9cf43a0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f08e9cf5ae0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f0929e8a410>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f08e91e0a00, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f0929e8a410>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f08e91e34c0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f08e91e0a00, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f0929e8a410>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f08e0471b10, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f0929e8a410>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f08e0470bb0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f08e0471b10, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f0929e8a410>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f08e93ce110, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f0929e8a410>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f08e93cf310, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f08e93ce110, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f0929e8a410>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f08e02d7df0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f0929e8a410>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f08e02d68c0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f08e02d7df0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f0929e8a410>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f09003528c0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f0929e8a410>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f08d17f6020, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f09003528c0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f0929e8a410>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f08e8471d50, raw_cell="# %%
# Step 5: Save the Fine-Tuned Model
model.sav.." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-1.interactive#X20sdW50aXRsZWQ%3D>,),kwargs {}:
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f0929e8a410>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f08e8473e50, execution_count=4 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f08e8471d50, raw_cell="# %%
# Step 5: Save the Fine-Tuned Model
model.sav.." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-1.interactive#X20sdW50aXRsZWQ%3D> result=('./gemma-2-2b-it_LoRa_synthetic-dataset/tokenizer_config.json', './gemma-2-2b-it_LoRa_synthetic-dataset/special_tokens_map.json', './gemma-2-2b-it_LoRa_synthetic-dataset/tokenizer.model', './gemma-2-2b-it_LoRa_synthetic-dataset/added_tokens.json', './gemma-2-2b-it_LoRa_synthetic-dataset/tokenizer.json')>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f0929e8a410>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f08e0e83970, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f0929e8a410>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f08e0e80d90, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f08e0e83970, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f0929e8a410>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f08d17f7760, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f0929e8a410>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f08d17f55d0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f08d17f7760, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f0929e8a410>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f08e1057550, raw_cell="#%%
from sae_lens import SAE
import torch
from tra.." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-1.interactive#X22sdW50aXRsZWQ%3D>,),kwargs {}:
