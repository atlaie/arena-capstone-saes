Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fea65e6e620>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fea38595000, execution_count=4 error_before_exec=None error_in_exec=Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`labels` in this case) have excessive nesting (inputs type `list` where type `int` is expected). info=<ExecutionInfo object at 7fea38595030, raw_cell="#%%
# ============================================.." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-2.interactive#X11sdW50aXRsZWQ%3D> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fea65e6e620>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fea23085ab0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fea65e6e620>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fea223d8700, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fea23085ab0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fea65e6e620>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fea65fa20b0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fea65e6e620>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fea65e82ad0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fea65fa20b0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fea65e6e620>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fea65e19030, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fea65e6e620>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fea2223e6b0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fea65e19030, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fea65e6e620>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fea222acd00, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fea65e6e620>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fea222acac0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fea222acd00, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fea65e6e620>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fea65ca2e90, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fea65e6e620>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fea65ca2020, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fea65ca2e90, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fea65e6e620>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fea3822fbe0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fea65e6e620>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fea380a1870, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fea3822fbe0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fea65e6e620>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fea223d8280, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fea65e6e620>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fea3812a1d0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fea223d8280, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fea65e6e620>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fea65fa20b0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fea65e6e620>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fea222af340, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fea65fa20b0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fea65e6e620>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fea65ce76a0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fea65e6e620>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fea223d8280, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fea65ce76a0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fea65e6e620>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fea65e81720, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fea65e6e620>> (for post_run_cell), with arguments args (<ExecutionResult object at 7fea223d8700, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fea65e81720, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fea65e6e620>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fea65eefdc0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoTokenizer", "type": "type", "fullType": "type"}, {"name": "DataCollatorForSeq2Seq", "type": "type", "fullType": "type"}, {"name": "DataLoader", "type": "type", "fullType": "type"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "HookedTransformer", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "batch_size", "type": "int", "fullType": "int"}, {"name": "data_collator", "type": "DataCollatorForSeq2Seq", "fullType": "transformers.data.data_collator.DataCollatorForSeq2Seq"}, {"name": "device", "type": "device", "fullType": "torch.device"}, {"name": "ds", "type": "DatasetDict", "fullType": "datasets.dataset_dict.DatasetDict"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "elem", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "ii", "type": "int", "fullType": "int"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_dataset", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "param", "type": "Parameter", "fullType": "torch.nn.parameter.Parameter"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "test_dataloader", "type": "DataLoader", "fullType": "torch.utils.data.dataloader.DataLoader"}, {"name": "tokenize_function_with_choices_test", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_test", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "trainable_parameters", "type": "list", "fullType": "list"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
