AUTOTUNE bmm(32x512x256, 32x256x512)
  bmm 0.1956 ms 100.0%
  triton_bmm_15 0.4854 ms 40.3%
  triton_bmm_9 0.4874 ms 40.1%
  triton_bmm_10 0.4936 ms 39.6%
  triton_bmm_13 0.4936 ms 39.6%
  triton_bmm_14 0.4997 ms 39.1%
  triton_bmm_6 0.5437 ms 36.0%
  triton_bmm_5 0.5560 ms 35.2%
  triton_bmm_18 0.6042 ms 32.4%
  triton_bmm_2 0.7844 ms 24.9%
SingleProcess AUTOTUNE benchmarking takes 15.8654 seconds and 0.0000 seconds precompiling
AUTOTUNE bmm(32x512x512, 32x512x256)
  bmm 0.1884 ms 100.0%
  triton_bmm_33 0.4864 ms 38.7%
  triton_bmm_29 0.5028 ms 37.5%
  triton_bmm_24 0.5530 ms 34.1%
  triton_bmm_32 0.5550 ms 33.9%
  triton_bmm_37 0.5550 ms 33.9%
  triton_bmm_25 0.5786 ms 32.6%
  triton_bmm_34 0.6154 ms 30.6%
  triton_bmm_28 0.6246 ms 30.2%
  triton_bmm_22 0.6963 ms 27.1%
SingleProcess AUTOTUNE benchmarking takes 15.7095 seconds and 0.0000 seconds precompiling
AUTOTUNE bmm(32x512x512, 32x512x256)
  bmm 0.1853 ms 100.0%
  triton_bmm_1031 0.5202 ms 35.6%
  triton_bmm_1032 0.6523 ms 28.4%
  triton_bmm_1029 0.7014 ms 26.4%
  triton_bmm_1028 0.7025 ms 26.4%
  triton_bmm_1035 0.7199 ms 25.7%
  triton_bmm_1039 0.7301 ms 25.4%
  triton_bmm_1040 0.7516 ms 24.7%
  triton_bmm_1036 0.7782 ms 23.8%
  triton_bmm_1033 0.7813 ms 23.7%
SingleProcess AUTOTUNE benchmarking takes 26.1210 seconds and 0.0000 seconds precompiling
<bound method Module.named_modules of PeftModelForCausalLM(
  (base_model): LoraModel(
    (model): Gemma2ForCausalLM(
      (model): Gemma2Model(
        (embed_tokens): Embedding(256000, 2304)
        (layers): ModuleList(
          (0-25): 26 x Gemma2DecoderLayer(
            (self_attn): Gemma2Attention(
              (q_proj): Linear(in_features=2304, out_features=2048, bias=False)
              (k_proj): Linear(in_features=2304, out_features=1024, bias=False)
              (v_proj): Linear(in_features=2304, out_features=1024, bias=False)
              (o_proj): Linear(in_features=2048, out_features=2304, bias=False)
              (rotary_emb): GemmaFixedRotaryEmbedding()
            )
            (mlp): Gemma2MLP(
              (gate_proj): lora.Linear(
                (base_layer): Linear(in_features=2304, out_features=9216, bias=False)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=2304, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=9216, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict()
              )
              (up_proj): lora.Linear(
                (base_layer): Linear(in_features=2304, out_features=9216, bias=False)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=2304, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=9216, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict()
              )
              (down_proj): lora.Linear(
                (base_layer): Linear(in_features=9216, out_features=2304, bias=False)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=9216, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=2304, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict()
              )
              (act_fn): PytorchGELUTanh()
            )
            (input_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)
            (post_attention_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)
            (pre_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)
            (post_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)
          )
        )
        (norm): Gemma2RMSNorm((2304,), eps=1e-06)
      )
      (lm_head): Linear(in_features=2304, out_features=256000, bias=False)
    )
  )
)>
Training completed in 2716.7826 seconds.
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f3854c8c850, execution_count=3 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f3854c8c730, raw_cell="#%%
trainer = SFTTrainer(
    model=model,
    to.." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-1.interactive#W3sdW50aXRsZWQ%3D> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f380484fd90, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f380484f970, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f380484fd90, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f38043401f0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38048076d0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f38043401f0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f3804860580, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f3804862530, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f3804860580, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f38567ca2c0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f3804816650, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f38567ca2c0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f384c438e20, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f3854822e60, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f384c438e20, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f38048c0790, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38048c04f0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f38048c0790, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f38049c6170, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38049c5210, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f38049c6170, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f3804878220, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f380487a770, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f3804878220, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f38043401f0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38049dc190, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f38043401f0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f3854822680, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f3854822e60, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f3854822680, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f38548225f0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38047ad030, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f38548225f0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f3804861b70, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38048614b0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f3804861b70, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f38049eb340, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38049ebf10, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f38049eb340, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f38048c0fd0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38048c0640, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f38048c0fd0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f38049b7a60, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38049b5930, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f38049b7a60, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f38048b31c0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38048b30d0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f38048b31c0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f384c5e6c20, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38049c43a0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f384c5e6c20, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f38048b1570, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38048b2e90, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f38048b1570, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f380498e260, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f380498d240, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f380498e260, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f383c421060, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38048c0580, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f383c421060, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f38048b1480, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38048b1de0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f38048b1480, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f3ad1e6f940, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f384c5e6c20, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f3ad1e6f940, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f3807e94580, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f380453ae00, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f3807e94580, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f3804879c90, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f3804878d30, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f3804879c90, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f38567c8e20, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38567ca380, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f38567c8e20, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f38047efc10, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f3804861cf0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f38047efc10, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f3ad03a1cc0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38049dd7b0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f3ad03a1cc0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f38048c0100, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38048c23b0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f38048c0100, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f38049e9090, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38049eb220, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f38049e9090, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f3804804cd0, raw_cell="# %%
from transformers import AutoModelForCausalL.." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-1.interactive#W6sdW50aXRsZWQ%3D>,),kwargs {}:
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38048049d0, execution_count=4 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f3804804cd0, raw_cell="# %%
from transformers import AutoModelForCausalL.." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-1.interactive#W6sdW50aXRsZWQ%3D> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f380482d510, raw_cell="#%%
import torch as t
t.sum(model.model.layers[-1.." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-1.interactive#X10sdW50aXRsZWQ%3D>,),kwargs {}:
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f380482ed70, execution_count=5 error_before_exec=None error_in_exec='Gemma2ForCausalLM' object has no attribute 'layers' info=<ExecutionInfo object at 7f380482d510, raw_cell="#%%
import torch as t
t.sum(model.model.layers[-1.." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-1.interactive#X10sdW50aXRsZWQ%3D> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f38047ed690, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38047ecf70, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f38047ed690, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f3807e94580, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f3807e968f0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f3807e94580, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f380489d780, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f380489e3b0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f380489d780, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f38248ba470, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f380482e080, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f38248ba470, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f3805ee08e0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f3804979660, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f3805ee08e0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f3805db08b0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f3805db07f0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f3805db08b0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f3807e95120, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f3807e95300, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f3807e95120, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f384c5e7460, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38048149d0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f384c5e7460, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f38048169b0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f3804816e60, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f38048169b0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f380de46c50, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f3807e968f0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f380de46c50, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f380497bee0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38049794b0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f380497bee0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f380483c550, raw_cell="#%%
import torch as t
t.sum(model.base_model.mode.." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-1.interactive#X11sdW50aXRsZWQ%3D>,),kwargs {}:
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f380483c0d0, execution_count=6 error_before_exec=None error_in_exec=Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! info=<ExecutionInfo object at 7f380483c550, raw_cell="#%%
import torch as t
t.sum(model.base_model.mode.." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-1.interactive#X11sdW50aXRsZWQ%3D> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f38048169b0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f3804817250, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f38048169b0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f3854cda920, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f3854cd9e70, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f3854cda920, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f3805d08fd0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f3805d0b850, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f3805d08fd0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f380497b1c0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f380497a3e0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f380497b1c0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f38045707c0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f3804d50d90, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f38045707c0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f380489e4a0, raw_cell="# %%
from transformers import AutoModelForCausalL.." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-1.interactive#X12sdW50aXRsZWQ%3D>,),kwargs {}:
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f380489ea70, execution_count=7 error_before_exec=None error_in_exec=name 'device' is not defined info=<ExecutionInfo object at 7f380489e4a0, raw_cell="# %%
from transformers import AutoModelForCausalL.." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-1.interactive#X12sdW50aXRsZWQ%3D> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f3804783250, raw_cell="#%%
import torch as t
t.sum(model.base_model.mode.." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-1.interactive#X13sdW50aXRsZWQ%3D>,),kwargs {}:
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38047808e0, execution_count=8 error_before_exec=None error_in_exec=Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! info=<ExecutionInfo object at 7f3804783250, raw_cell="#%%
import torch as t
t.sum(model.base_model.mode.." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-1.interactive#X13sdW50aXRsZWQ%3D> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f3804781ff0, raw_cell="# %%
from transformers import AutoModelForCausalL.." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-1.interactive#X14sdW50aXRsZWQ%3D>,),kwargs {}:
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f3804783a90, execution_count=9 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f3804781ff0, raw_cell="# %%
from transformers import AutoModelForCausalL.." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-1.interactive#X14sdW50aXRsZWQ%3D> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f38048b3130, raw_cell="#%%
import torch as t
t.sum(model.base_model.mode.." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-1.interactive#X15sdW50aXRsZWQ%3D>,),kwargs {}:
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38048b1e40, execution_count=10 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f38048b3130, raw_cell="#%%
import torch as t
t.sum(model.base_model.mode.." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-1.interactive#X15sdW50aXRsZWQ%3D> result=tensor(-0.4033, device='cuda:0', grad_fn=<SumBackward0>)>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f380479a0b0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f3804799060, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f380479a0b0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f380479b580, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38047980d0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f380479b580, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f3804799060, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f380479a0b0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f3804799060, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f3ad03a1cc0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38043401f0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f3ad03a1cc0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f380de46c50, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f383c421060, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f380de46c50, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f384c5e6c20, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f380462a3e0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f384c5e6c20, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f380489e860, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f380489eb30, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f380489e860, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f380483ec20, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f380483eef0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f380483ec20, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f3807bdeaa0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f3807bdfd90, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f3807bdeaa0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f380483cbb0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f380483da20, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f380483cbb0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f37fff0db40, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f37fff0d780, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f37fff0db40, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f380483d870, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f380483e650, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f380483d870, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f38048b3310, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38048b2fe0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f38048b3310, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f380483d750, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f380483ec20, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f380483d750, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f3804805a80, raw_cell="#%%
model.save_pretrained("gemma-2-2b-it_noLoRa")
" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-1.interactive#X16sdW50aXRsZWQ%3D>,),kwargs {}:
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f3804805fc0, execution_count=11 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f3804805a80, raw_cell="#%%
model.save_pretrained("gemma-2-2b-it_noLoRa")
" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-1.interactive#X16sdW50aXRsZWQ%3D> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f380479b7f0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38047980d0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f380479b7f0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f3805db2ef0, raw_cell="#%%
model
" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-1.interactive#X20sdW50aXRsZWQ%3D>,),kwargs {}:
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f3805db0b20, execution_count=12 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f3805db2ef0, raw_cell="#%%
model
" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-1.interactive#X20sdW50aXRsZWQ%3D> result=PeftModelForCausalLM(
  (base_model): LoraModel(
    (model): Gemma2ForCausalLM(
      (model): Gemma2Model(
        (embed_tokens): Embedding(256000, 2304)
        (layers): ModuleList(
          (0-25): 26 x Gemma2DecoderLayer(
            (self_attn): Gemma2Attention(
              (q_proj): Linear(in_features=2304, out_features=2048, bias=False)
              (k_proj): Linear(in_features=2304, out_features=1024, bias=False)
              (v_proj): Linear(in_features=2304, out_features=1024, bias=False)
              (o_proj): Linear(in_features=2048, out_features=2304, bias=False)
              (rotary_emb): GemmaFixedRotaryEmbedding()
            )
            (mlp): Gemma2MLP(
              (gate_proj): lora.Linear(
                (base_layer): Linear(in_features=2304, out_features=9216, bias=False)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=2304, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=9216, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict()
              )
              (up_proj): lora.Linear(
                (base_layer): Linear(in_features=2304, out_features=9216, bias=False)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=2304, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=9216, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict()
              )
              (down_proj): lora.Linear(
                (base_layer): Linear(in_features=9216, out_features=2304, bias=False)
                (lora_dropout): ModuleDict(
                  (default): Identity()
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=9216, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=2304, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict()
              )
              (act_fn): PytorchGELUTanh()
            )
            (input_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)
            (post_attention_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)
            (pre_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)
            (post_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)
          )
        )
        (norm): Gemma2RMSNorm((2304,), eps=1e-06)
      )
      (lm_head): Linear(in_features=2304, out_features=256000, bias=False)
    )
  )
)>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f38049ddba0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38049dec50, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f38049ddba0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f382c29e440, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f383c421060, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f382c29e440, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f38049de4a0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f38049dcee0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f38049de4a0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f38049e9ba0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f380483e800, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f38049e9ba0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f384c43a2f0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
[{"name": "AutoModelForCausalLM", "type": "type", "fullType": "type"}, {"name": "DATA_SEED", "type": "int", "fullType": "int"}, {"name": "Dataset", "type": "type", "fullType": "type"}, {"name": "FastLanguageModel", "type": "type", "fullType": "type"}, {"name": "SFTTrainer", "type": "type", "fullType": "type"}, {"name": "TrainingArguments", "type": "type", "fullType": "type"}, {"name": "dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "dtype", "type": "NoneType", "fullType": "NoneType"}, {"name": "full_synthetic_wmdp", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "get_ipython", "type": "function", "fullType": "function"}, {"name": "is_bfloat16_supported", "type": "function", "fullType": "function"}, {"name": "load_in_4bit", "type": "bool", "fullType": "bool"}, {"name": "max_seq_length", "type": "int", "fullType": "int"}, {"name": "model", "type": "PeftModelForCausalLM", "fullType": "peft.peft_model.PeftModelForCausalLM"}, {"name": "model_base", "type": "Gemma2ForCausalLM", "fullType": "transformers.models.gemma2.modeling_gemma2.Gemma2ForCausalLM"}, {"name": "os", "type": "module", "fullType": "module"}, {"name": "pd", "type": "module", "fullType": "module"}, {"name": "t", "type": "module", "fullType": "module"}, {"name": "tokenize_function_with_choices", "type": "function", "fullType": "function"}, {"name": "tokenized_dataset_train", "type": "Dataset", "fullType": "datasets.arrow_dataset.Dataset"}, {"name": "tokenizer", "type": "GemmaTokenizerFast", "fullType": "transformers.models.gemma.tokenization_gemma_fast.GemmaTokenizerFast"}, {"name": "torch", "type": "module", "fullType": "module"}, {"name": "train_data", "type": "DataFrame", "fullType": "pandas.core.frame.DataFrame"}, {"name": "trainer", "type": "SFTTrainer", "fullType": "trl.trainer.sft_trainer.SFTTrainer"}, {"name": "trainer_stats", "type": "TrainOutput", "fullType": "transformers.trainer_utils.TrainOutput"}, {"name": "use_bfloat16", "type": "bool", "fullType": "bool"}]
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f384c438f40, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f384c43a2f0, raw_cell="def _VSCODE_getVariable(what_to_get, is_debugging,.." store_history=False silent=False shell_futures=True cell_id=None> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f3804d52980, raw_cell="#%%
from inspect_ai import eval_set
from inspect_a.." store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Interactive-1.interactive#X21sdW50aXRsZWQ%3D>,),kwargs {}:
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3854821f90>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f3804d50df0, execution_count=13 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f3804d52980, raw_cell="#%%
from inspect_ai import eval_set
